{
    "componentChunkName": "component---src-templates-post-js",
    "path": "/deep/gnn-scratch/",
    "result": {"data":{"mdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"gnns-almost-from-scratch\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h1\",\n    \"href\": \"#gnns-almost-from-scratch\",\n    \"aria-label\": \"gnns almost from scratch permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"GNNs almost from scratch\"), mdx(\"h2\", {\n    \"id\": \"collating-batching-graphs\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#collating-batching-graphs\",\n    \"aria-label\": \"collating batching graphs permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Collating (batching) graphs\"), mdx(\"deckgo-highlight-code\", {\n    \"language\": \"python\",\n    \"theme\": \"nord\",\n    \"line-numbers\": \"true\"\n  }, \"\\n          \", mdx(\"code\", {\n    parentName: \"deckgo-highlight-code\",\n    \"slot\": \"code\"\n  }, \"def collate_graphs(batch):\\n    \\\"\\\"\\\"\\n    Batch multiple graphs into one batched graph.\\n    \\n    Args:\\n        batch (tuple): tuples of AtomicNum, Edge, Natom and y obtained from\\n            GraphDataset.__getitem__() \\n        \\n    Return \\n        (tuple): Batched AtomicNum, Edge, Natom, y\\n    \\\"\\\"\\\"\\n    \\n    AtomicNum_batch = []\\n    Edge_batch = []\\n    Natom_batch = []\\n    y_batch = []\\n\\n    cumulative_atoms = np.cumsum([0] + [b[2] for b in batch])[:-1]\\n    \\n    for i in range(len(batch)):\\n        z, a, N, y = batch[i]\\n        index_shift = cumulative_atoms[i]\\n        a = a + index_shift\\n        AtomicNum_batch.append(z) \\n        Edge_batch.append(a)\\n        Natom_batch.append(N)\\n        y_batch.append(y)\\n        \\n    AtomicNum_batch = torch.cat(AtomicNum_batch)\\n    Edge_batch = torch.cat(Edge_batch, dim=1)\\n    Natom_batch = Natom_batch # i.e. no changes made\\n    y_batch = torch.cat(y_batch)\\n    \\n    return AtomicNum_batch, Edge_batch, Natom_batch, y_batch \"), \"\\n        \"), mdx(\"h2\", {\n    \"id\": \"scatter-add\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#scatter-add\",\n    \"aria-label\": \"scatter add permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Scatter add\"), mdx(\"p\", null, \"The main function driving fast implementations of graph neural networks is \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"scatter_add\"), \".\"), mdx(\"deckgo-highlight-code\", {\n    \"language\": \"python\",\n    \"theme\": \"nord\",\n    \"line-numbers\": \"true\"\n  }, \"\\n          \", mdx(\"code\", {\n    parentName: \"deckgo-highlight-code\",\n    \"slot\": \"code\"\n  }, \"def scatter_add(src, index, dim_size, dim=-1, fill_value=0):\\n    \\\"\\\"\\\"\\n    Sums all values from the src tensor into out at the indices specified in the index \\n    tensor along a given axis dim. \\n    \\\"\\\"\\\"\\n    \\n    # make index the same shape as src\\n    # this will make `scatter_add_` add vectors from `src` to `out`\\n    index_size = list(repeat(1, src.dim()))\\n    index_size[dim] = src.size(dim)\\n    index = index.view(index_size).expand_as(src)\\n    \\n    # create the shape of the out vector\\n    # out will have shape src.size() but with `dim` changed to dim_size\\n    # e.g.\\n    #    - src contains 1 row vector for each edge,\\n    #    - out's rows should have the same dim as those vectors,\\n    #      but the number of rows should be the number of nodes,\\n    #      not the number of edges\\n    dim = range(src.dim())[dim] # convert -1 to actual dim number\\n    out_size = list(src.size())\\n    out_size[dim] = dim_size\\n\\n    out = src.new_full(out_size, fill_value)\\n\\n    return out.scatter_add_(dim, index, src)\"), \"\\n        \"), mdx(\"h3\", {\n    \"id\": \"graph-neural-network-pytorch-module\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#graph-neural-network-pytorch-module\",\n    \"aria-label\": \"graph neural network pytorch module permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Graph Neural Network PyTorch module\"), mdx(\"deckgo-highlight-code\", {\n    \"language\": \"python\",\n    \"theme\": \"nord\",\n    \"line-numbers\": \"true\"\n  }, \"\\n          \", mdx(\"code\", {\n    parentName: \"deckgo-highlight-code\",\n    \"slot\": \"code\"\n  }, \"rom torch import nn\\nfrom torch.nn import ModuleDict\\n\\nclass GNN(nn.Module):\\n    \\\"\\\"\\\"\\n    A GNN model.\\n    \\\"\\\"\\\"\\n    def __init__(self, n_convs=3, n_embed=64):\\n        super(GNN, self).__init__()\\n        \\n        self.atom_embed = nn.Embedding(100, n_embed)\\n\\n        # declare MLPs (linear layers) in a ModuleList\\n        self.convolutions = nn.ModuleList([ \\n                ModuleDict({\\n                    \\\"update_mlp\\\": nn.Sequential(\\n                        nn.Linear(n_embed, n_embed), \\n                        nn.ReLU(), \\n                        nn.Linear(n_embed, n_embed)\\n                        ),\\n                    \\\"message_mlp\\\": nn.Sequential(\\n                        nn.Linear(n_embed, n_embed), \\n                        nn.ReLU(), \\n                        nn.Linear(n_embed, n_embed)\\n                        ) \\n                })\\n                for _ in range(n_convs)\\n            ])\\n        # Declare readout layers\\n        self.readout = nn.Sequential(\\n            nn.Linear(n_embed, n_embed),\\n            nn.ReLU(),\\n            nn.Linear(n_embed, 1)\\n            )\\n        \\n    def forward(self, atomic_num, edge, Natom):\\n        # - take atomic numbers and convert into their \\\"word embeddings\\\"\\n        # - these word embeddings will be modified during training\\n        h = self.atom_embed(atomic_num)       # shape=(Natom, n_embed)\\n        \\n        for conv in self.convolutions:\\n            prod = h[edge[0]] * h[edge[1]]    # shape=(Nedge, n_embed)\\n            msgs = conv[\\\"message_mlp\\\"](prod)  # shape=(Nedge, n_embed)\\n\\n            # - send the messages to nodes, undirected graph\\n            # - sum(Natom) is needed because we collated the graph\\n            agg_msg = scatter_add(src=msgs, index=edge[1], dim=0, dim_size=sum(Natom)) + \\\\\\n                      scatter_add(src=msgs, index=edge[0], dim=0, dim_size=sum(Natom))\\n            \\n            # - transform the message using UpdateMLP, and add as a\\n            #   residual connection\\n            h += conv[\\\"update_mlp\\\"](agg_msg)\\n        \\n        readout = self.readout(h)\\n\\n        # - split readout to get the readout for each individual graph\\n        #   in the batch\\n        readout_split = torch.split(readout, Natom)\\n        output = torch.stack(\\n            [split.sum(0) for split in readout_split],\\n            dim=0\\n            ).squeeze()\\n        \\n        return output\"), \"\\n        \"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":""}}},"pageContext":{"slug":"deep/gnn-scratch/"}},
    "staticQueryHashes": []}